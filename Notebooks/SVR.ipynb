{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Support Vector Regression\n",
    " "
   ],
   "id": "a348b91517f43240"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-18T12:00:19.139492Z",
     "start_time": "2024-10-18T12:00:19.125402Z"
    }
   },
   "source": [
    "import  os\n",
    "import  numpy as np\n",
    "import  pandas as pd\n",
    "import  matplotlib.pyplot as plt\n",
    "import  seaborn as sns\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T12:00:19.202343Z",
     "start_time": "2024-10-18T12:00:19.140999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('../data_preprocessing/Merged_data/002_verwaltung_with_holidays.csv')\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'], format='%Y-%m-%d %H:%M:%S')"
   ],
   "id": "7428142abb67464a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T12:00:19.218306Z",
     "start_time": "2024-10-18T12:00:19.204355Z"
    }
   },
   "cell_type": "code",
   "source": "df.set_index('DateTime',inplace=True)\n",
   "id": "fe7e34807c56eb1f",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T12:00:19.233947Z",
     "start_time": "2024-10-18T12:00:19.218306Z"
    }
   },
   "cell_type": "code",
   "source": "df = df.astype({'is_holiday': 'int32', 'day_of_week': 'int32', 'hour_of_day': 'int32', 'is_working_hour': 'int32'})",
   "id": "645c96490abb3580",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T12:00:19.249137Z",
     "start_time": "2024-10-18T12:00:19.234946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the date ranges for training and test data\n",
    "train_end_date = df.index.min() + pd.DateOffset(months=9)\n",
    "test_start_date = train_end_date\n",
    "\n",
    "# Split the DataFrame\n",
    "train_data = df[:train_end_date]\n",
    "test_data = df[test_start_date:]"
   ],
   "id": "4076de4b16925475",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T12:00:45.928213Z",
     "start_time": "2024-10-18T12:00:19.250143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Prepare the data\n",
    "input_cols = [ 'Temperature',\n",
    "       'Humidity', 'Dewpoint', 'Sun Duration', 'Precipitation Height',\n",
    "       'Wind Speed', 'Wind Direction']\n",
    "target_col = 'heating_15min_diff'\n",
    "\n",
    "# Assuming train_data and test_data are already loaded DataFrames\n",
    "X_train = train_data[input_cols]\n",
    "y_train = train_data[target_col]\n",
    "X_test = test_data[input_cols]\n",
    "y_test = test_data[target_col]\n",
    "\n",
    "# Train the SVR model\n",
    "svr = SVR(kernel='rbf')\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MSE: {mse:.4f}')\n",
    "print(f'MAE: {mae:.4f}')\n",
    "print(f'R² Score: {r2:.4f}')"
   ],
   "id": "71ee7b7268fb56fa",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 18\u001B[0m\n\u001B[0;32m     15\u001B[0m svr\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Make predictions\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43msvr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# Evaluate the model\u001B[39;00m\n\u001B[0;32m     21\u001B[0m mse \u001B[38;5;241m=\u001B[39m mean_squared_error(y_test, y_pred)\n",
      "File \u001B[1;32mD:\\Users\\guoqi\\miniconda3\\envs\\py38\\lib\\site-packages\\sklearn\\svm\\_base.py:433\u001B[0m, in \u001B[0;36mBaseLibSVM.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    431\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_for_predict(X)\n\u001B[0;32m    432\u001B[0m predict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sparse_predict \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sparse \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dense_predict\n\u001B[1;32m--> 433\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Users\\guoqi\\miniconda3\\envs\\py38\\lib\\site-packages\\sklearn\\svm\\_base.py:452\u001B[0m, in \u001B[0;36mBaseLibSVM._dense_predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    444\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    445\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX.shape[1] = \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m should be equal to \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    446\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe number of samples at training time\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    447\u001B[0m             \u001B[38;5;241m%\u001B[39m (X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape_fit_[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m    448\u001B[0m         )\n\u001B[0;32m    450\u001B[0m svm_type \u001B[38;5;241m=\u001B[39m LIBSVM_IMPL\u001B[38;5;241m.\u001B[39mindex(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_impl)\n\u001B[1;32m--> 452\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlibsvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    453\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    454\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msupport_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    455\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msupport_vectors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    456\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_n_support\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dual_coef_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    458\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_intercept_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    459\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_probA\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_probB\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    461\u001B[0m \u001B[43m    \u001B[49m\u001B[43msvm_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msvm_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    462\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkernel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    463\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdegree\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdegree\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    464\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcoef0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoef0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    465\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgamma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gamma\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    466\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    467\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a DataFrame with actual and predicted values\n",
    "df_results = pd.DataFrame({\n",
    "    'Time Step': range(len(y_test)),\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred\n",
    "})\n",
    "\n",
    "# Plot using Matplotlib\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_results['Time Step'], df_results['Actual'], label='Actual', color='b')\n",
    "plt.plot(df_results['Time Step'], df_results['Predicted'], label='Predicted', color='r', linestyle='--')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Heating 15min Diff')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "c56bb97a59e5da36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ae4a1b0c6f7d1392",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Using holidays as a feature",
   "id": "b84d9f2d8cca47e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare the data\n",
    "input_cols = [ 'is_holiday',\n",
    "       'day_of_week', 'hour_of_day', 'is_working_hour', 'Temperature',\n",
    "       'Humidity', 'Dewpoint', 'Sun Duration', 'Precipitation Height',\n",
    "       'Wind Speed', 'Wind Direction']\n",
    "target_col = 'heating_15min_diff'\n",
    "\n",
    "# Assuming train_data and test_data are already loaded DataFrames\n",
    "X_train = train_data[input_cols]\n",
    "y_train = train_data[target_col]\n",
    "X_test = test_data[input_cols]\n",
    "y_test = test_data[target_col]\n",
    "\n",
    "# Train the SVR model\n",
    "svr = SVR(kernel='rbf')\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MSE: {mse:.4f}')\n",
    "print(f'MAE: {mae:.4f}')\n",
    "print(f'R² Score: {r2:.4f}')"
   ],
   "id": "48ad688b8ce9ad03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Assuming `y_test` and `y_pred` are your actual and predicted values respectively\n",
    "\n",
    "# Convert to numpy arrays if they are not already\n",
    "y_test = np.array(y_test)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Plot the actual vs predicted values\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(y_test, label='Actual', color='b')\n",
    "plt.plot(y_pred, label='Predicted', color='r', linestyle='--')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Electricity 15min Diff')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "f219c35fd35df436",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "# Calculate permutation importance\n",
    "perm_importance = permutation_importance(svr, X_test, y_test, n_repeats=30, random_state=42)\n",
    "\n",
    "# Create a DataFrame for the feature importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': input_cols,\n",
    "    'Importance': perm_importance.importances_mean\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances)\n",
    "plt.title('Feature Importance using Permutation Importance')\n",
    "plt.show()"
   ],
   "id": "dcd5ade9cb636ad0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a83efa209607f58e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
